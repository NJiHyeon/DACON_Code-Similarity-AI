{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d2b3ad9-6bf7-4da8-9610-cd0abfb7a054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 13 13:19:15 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   37C    P0    62W / 300W |  16425MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\n",
      "| N/A   40C    P0    64W / 300W |  14748MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:07.0 Off |                  Off |\n",
      "| N/A   41C    P0    68W / 300W |  14695MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     18593      C   ...u/anaconda3/bin/python3.9    16423MiB |\n",
      "|    1   N/A  N/A     18593      C   ...u/anaconda3/bin/python3.9    14745MiB |\n",
      "|    2   N/A  N/A     18593      C   ...u/anaconda3/bin/python3.9    14693MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41379d25-e4dc-4aee-9915-c6f76f592586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca1d1969-92ce-4c49-bc4c-c43918b20ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf687e-9050-4d9f-a0d8-327e760f196c",
   "metadata": {},
   "source": [
    "패키지 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab3047b-4690-4e93-9cee-1e837ce7f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/lib/python3.9/site-packages (4.19.2)\n",
      "Requirement already satisfied: datasets in /home/ubuntu/anaconda3/lib/python3.9/site-packages (1.17.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets) (2021.8.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: dill in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/lib/python3.9/site-packages (4.19.2)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9706edc8-abfc-4728-bd11-5533c2f9086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from itertools import combinations\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "from datasets import load_dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ad20ab-bcf2-480c-bf48-f90f8865b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed = 42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15929e0f-1d70-4efb-85db-acb19b26ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '/home/ubuntu/HwangJaewon/DL_class/code/'\n",
    "code_file = os.listdir(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ecd02f-dd06-453a-85e1-750f20f631aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5133767"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/home/ubuntu/HwangJaewon/DL_class/train_data.csv\")\n",
    "train.head()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3e9831-e2f5-44ed-bf53-897d8c12b79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"/home/ubuntu/HwangJaewon/DL_class/test.csv\")\n",
    "test.head()\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02dcf781-c66a-4e35-9dd5-7a39a0f85fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 183.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_script(script):\n",
    "    '''\n",
    "    간단한 전처리 함수\n",
    "    주석 -> 삭제\n",
    "    '    '-> tab 변환\n",
    "    다중 개행 -> 한 번으로 변환\n",
    "    '''\n",
    "    with open(script,'r',encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        preproc_lines = []\n",
    "        for line in lines:\n",
    "            if line.lstrip().startswith('#'): # #으로 시작하면 -> pass\n",
    "                continue\n",
    "            line = line.rstrip()\n",
    "            if '#' in line: # 중간에 #이 있으면 #전까지 indexing\n",
    "                line = line[:line.index('#')]\n",
    "            line = line.replace('\\n','') # \\n -> ''\n",
    "            line = line.replace('    ','\\t') # '     ' -> \\t로\n",
    "            if line == '':\n",
    "                continue\n",
    "            preproc_lines.append(line)\n",
    "        preprocessed_script = '\\n'.join(preproc_lines)\n",
    "    return preprocessed_script\n",
    "\n",
    "preproc_scripts = []\n",
    "problem_nums = []\n",
    "\n",
    "for problem_folder in tqdm(code_file):\n",
    "    scripts = os.listdir(os.path.join(code,problem_folder))\n",
    "    problem_num = scripts[0].split('_')[0]\n",
    "    for script in scripts:\n",
    "        script_file = os.path.join(code,problem_folder,script)\n",
    "        preprocessed_script = preprocess_script(script_file)\n",
    "\n",
    "        preproc_scripts.append(preprocessed_script)\n",
    "    problem_nums.extend([problem_num]*len(scripts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df930df4-b069-4d49-82e6-6ff82aaeb67c",
   "metadata": {},
   "source": [
    "코드 데이터에서 ''' ''' or \"\"\" \"\"\" 으로 긴 문장을 주석처리한 경우 삭제를 위해 추가로 전처리 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a5a10b-4420-4b1a-9722-6c38fdcb6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_scripts\n",
    "i = 0\n",
    "for c in preproc_scripts:\n",
    "      if \"'''\" in c: # code에 '''가 있으면 -> 다음 '''가 나타날 때 까지의 index로 slicing\n",
    "        c = c[c.rfind(\"'''\")+1:]\n",
    "      if '\"\"\"' in c:\n",
    "        c = c[c.rfind('\"\"\"')+1:]  # code에 \"\"\"가 있으면 -> 다음 \"\"\"가 나타날 때 까지의 index로 slicing\n",
    "      preproc_scripts[i] = c\n",
    "      i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bde6d0-3a75-4b05-8e66-174d720187f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'code':preproc_scripts, 'problem_num':problem_nums})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4046a39c-a15b-4c92-bf2c-71e1b6ad355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "tokenizer.truncation_side = \"left\"\n",
    "df['tokens'] = df['code'].apply(tokenizer.tokenize)\n",
    "df['len'] = df['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "099fd1f1-8c90-4f37-b60b-298e2069aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = df[df['len'] <= 512].reset_index(drop=True)\n",
    "ndf.to_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "226bf4b2-1a53-4ec3-bea4-150e2d5c0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = pd.read_csv('train_data.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dfd966-74d7-4709-919b-f93ab43671e6",
   "metadata": {},
   "source": [
    "정제된 학습 데이터 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2826cf9f-c54d-446a-a353-3ee55e11a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "valid = []\n",
    "\n",
    "kfold = StratifiedKFold(random_state = 42, shuffle = True)\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(kfold.split(ndf[\"code\"], ndf['problem_num'])):\n",
    "  X_train, X_val = ndf[\"code\"].iloc[train_idx],  ndf[\"code\"].iloc[val_idx]\n",
    "  y_train, y_val = ndf['problem_num'].iloc[train_idx], ndf['problem_num'].iloc[val_idx]\n",
    "\n",
    "  train_fold = pd.concat([X_train, y_train], axis = 1)\n",
    "  valid_fold = pd.concat([X_val, y_val], axis = 1)\n",
    "  train.append(train_fold)\n",
    "  valid.append(valid_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604c596-8703-478c-af43-9aca9b788510",
   "metadata": {},
   "source": [
    "Fold 앙상블을 위해 정제된 데이터 나누기(실험 여건상 5 fold 진행)\n",
    "이후의 코드는 fold 별로 나누어서 실행 5 fold라서 5번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfa14339-2889-458a-963d-dd5fc6ef6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[2].reset_index(drop=True)\n",
    "valid_df = valid[2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f340748-8931-4ad6-9b57-d789c486bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = train_df['code'].to_list()\n",
    "problems = train_df['problem_num'].unique().tolist()\n",
    "problems.sort()\n",
    "\n",
    "tokenized_corpus = [tokenizer.tokenize(code) for code in codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa048d6-6df1-4eaf-b575-0f02bb125407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problem216    122\n",
       "problem059    122\n",
       "problem062    122\n",
       "problem144    122\n",
       "problem082    122\n",
       "             ... \n",
       "problem210     72\n",
       "problem209     67\n",
       "problem112     64\n",
       "problem113     63\n",
       "problem034     57\n",
       "Name: problem_num, Length: 300, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.problem_num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363b603-80eb-4e55-b7b2-4f5bbe3c654c",
   "metadata": {},
   "source": [
    "Pair data 생성 전, 각 problem의 개수 확인 57 ~ 122개 사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08294c53-a095-4f41-8105-e22847b8f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:23<00:00, 12.97it/s]\n"
     ]
    }
   ],
   "source": [
    "total_positive_pairs= []\n",
    "total_negative_pairs = []\n",
    "for problem in tqdm(problems):\n",
    "    solution_codes = train_df[train_df['problem_num'] == problem]['code']\n",
    "    negative_codes = train_df[train_df['problem_num'] != problem]['code']\n",
    "    positive_pairs = list(combinations(solution_codes.to_list(),2))\n",
    "    positive_samples = random.sample(positive_pairs,round(len(positive_pairs)*0.025))\n",
    "\n",
    "    negative_samples = []\n",
    "    for i in range(round(len(positive_pairs)*0.025)):\n",
    "      code1 = random.choice(solution_codes.to_list())\n",
    "      code2 = random.choice(negative_codes.to_list())\n",
    "      pair = (code1, code2)\n",
    "      negative_samples.append(pair)\n",
    "    \n",
    "    total_positive_pairs.extend(positive_samples)\n",
    "    total_negative_pairs.extend(negative_samples)\n",
    "\n",
    "pos_code1 = list(map(lambda x:x[0],total_positive_pairs))\n",
    "pos_code2 = list(map(lambda x:x[1],total_positive_pairs))\n",
    "\n",
    "neg_code1 = list(map(lambda x:x[0],total_negative_pairs))\n",
    "neg_code2 = list(map(lambda x:x[1],total_negative_pairs))\n",
    "\n",
    "pos_label = [1]*len(pos_code1)\n",
    "neg_label = [0]*len(neg_code1)\n",
    "\n",
    "pos_code1.extend(neg_code1)\n",
    "total_code1 = pos_code1\n",
    "pos_code2.extend(neg_code2)\n",
    "total_code2 = pos_code2\n",
    "pos_label.extend(neg_label)\n",
    "total_label = pos_label\n",
    "pair_data = pd.DataFrame(data={\n",
    "    'code1':total_code1,\n",
    "    'code2':total_code2,\n",
    "    'similar':total_label\n",
    "})\n",
    "pair_data = pair_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370e3e7-6e97-4a40-a347-ee8f67485c70",
   "metadata": {},
   "source": [
    "Pair data를 만드는 과정 -> Random Sampling\n",
    "Positive pair - Problem number가 같은 것끼리 combination을 사용하여 pair를 만들고 그 중 특정 비율만큼 채택\n",
    "ex) 같은 1번 문제의 코드가 100개 있을 경우 1번 문제의 combination 총 개수 (100x99)/2 = 4950개에서 특정 비율만큼 random하게 선택, 비율이 0.025면 4950x0.025 = 약124개 선택 -> 100개의 1번 문제 코드에서 124개의 정답지가 생성\n",
    "Negative pair - Iteration에서 해당 번호의 코드에서 하나, 해당 번호가 아닌 코드에서 하나를 random하게 하나씩 채택\n",
    "ex) 1번 문제의 iteration일 경우, positive pair에서 만들어진 124번만큼 1번 문제에서 하나를 선택하고, 2번~300번의 모든 데이터에서 random하게 하나의 코드 선택 => 생성된 정답지 만큼의 오답지 생성\n",
    "비율 0.1 => 약 40만개 데이터 생성\n",
    "비율 0.05 => 약 20만개 데이터 생성\n",
    "비율 0.025 => 약 10만개 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1457bf75-c296-4f2f-9fd9-1f1fb0580fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_data.to_csv('train_data_fold4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "717c343f-d69f-4293-bb12-97b582449172",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = valid_df['code'].to_list()\n",
    "problems = valid_df['problem_num'].unique().tolist()\n",
    "problems.sort()\n",
    "\n",
    "tokenized_corpus = [tokenizer.tokenize(code) for code in codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bfcc8b6-40f0-4878-8087-18b065473895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 218.69it/s]\n"
     ]
    }
   ],
   "source": [
    "total_positive_pairs = []\n",
    "total_negative_pairs = []\n",
    "\n",
    "for problem in tqdm(problems):\n",
    "    solution_codes = valid_df[valid_df['problem_num'] == problem]['code']\n",
    "    negative_codes = valid_df[valid_df['problem_num'] != problem]['code']\n",
    "    positive_pairs = list(combinations(solution_codes.to_list(),2))\n",
    "    positive_samples = random.sample(positive_pairs,round(len(positive_pairs)*0.05))\n",
    "\n",
    "    negative_samples = []\n",
    "    for i in range(round(len(positive_pairs)*0.05)):\n",
    "      code1 = random.choice(solution_codes.to_list())\n",
    "      code2 = random.choice(negative_codes.to_list())\n",
    "      pair = (code1, code2)\n",
    "      negative_samples.append(pair)\n",
    "    \n",
    "    total_positive_pairs.extend(positive_samples)\n",
    "    total_negative_pairs.extend(negative_samples)\n",
    "\n",
    "\n",
    "pos_code1 = list(map(lambda x:x[0],total_positive_pairs))\n",
    "pos_code2 = list(map(lambda x:x[1],total_positive_pairs))\n",
    "\n",
    "neg_code1 = list(map(lambda x:x[0],total_negative_pairs))\n",
    "neg_code2 = list(map(lambda x:x[1],total_negative_pairs))\n",
    "\n",
    "pos_label = [1]*len(pos_code1)\n",
    "neg_label = [0]*len(neg_code1)\n",
    "\n",
    "pos_code1.extend(neg_code1)\n",
    "total_code1 = pos_code1\n",
    "pos_code2.extend(neg_code2)\n",
    "total_code2 = pos_code2\n",
    "pos_label.extend(neg_label)\n",
    "total_label = pos_label\n",
    "pair_data = pd.DataFrame(data={\n",
    "    'code1':total_code1,\n",
    "    'code2':total_code2,\n",
    "    'similar':total_label\n",
    "})\n",
    "pair_data = pair_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80eb60-7860-4114-a6c0-87769c92f698",
   "metadata": {},
   "source": [
    "Validation data의 생성 또한 같은 방법으로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ad063b-ad48-41b3-8482-d6a9bc304925",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_data.to_csv('valid_data_fold4.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd17f18-90e8-411f-8fdb-f51e4c8bf6c3",
   "metadata": {},
   "source": [
    "Model - Microsoft/graphcodebert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf903f0-6c0b-46ad-b3a0-c050e2168742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c72add23350714be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/ubuntu/.cache/huggingface/datasets/csv/default-c72add23350714be/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad4c0be16224203b13f608d3d80f5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8c73e234f14c95a1f92c1d75969255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/csv/default-c72add23350714be/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee581d500cc4b4cb232ae748965e5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = \"microsoft/graphcodebert-base\"\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': 'train_data_fold4.csv', 'test':  'valid_data_fold4.csv'})\n",
    "MAX_LEN = 512\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5296be72-e2d9-481f-be89-70794485578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function example_fn at 0x7f80f75c75e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec07f6ccc404815a62e6d4ab1694378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102396 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547774e79e3d44d28c843d93974493c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12578 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def example_fn(examples):\n",
    "    outputs = tokenizer(examples['code1'], examples['code2'], padding=True, max_length=MAX_LEN,truncation=True)\n",
    "    if 'similar' in examples:\n",
    "        outputs[\"labels\"] = examples[\"similar\"]\n",
    "    return outputs\n",
    "\n",
    "dataset = dataset.map(example_fn, remove_columns=['code1', 'code2', 'similar'])\n",
    "\n",
    "_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "_metric = load_metric(\"glue\", \"sst2\")\n",
    "\n",
    "def metric_fn(p):\n",
    "    preds, labels = p\n",
    "    output =  _metric.compute(references=labels, predictions=np.argmax(preds, axis=-1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdeb4df4-9a27-4030-b533-a9cfaba8f448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 102396\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21340\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhwangjaewon\u001b[0m (\u001b[33mprivate_repo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/nozzi/Dacon(code_s)/wandb/run-20220613_075309-iqtxbova</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/private_repo/huggingface/runs/iqtxbova\" target=\"_blank\">runs/</a></strong> to <a href=\"https://wandb.ai/private_repo/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21340' max='21340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21340/21340 3:25:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.979488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.073771</td>\n",
       "      <td>0.982032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.060970</td>\n",
       "      <td>0.982589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.062232</td>\n",
       "      <td>0.985928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.071118</td>\n",
       "      <td>0.986405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.083101</td>\n",
       "      <td>0.987359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.106893</td>\n",
       "      <td>0.983066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.090328</td>\n",
       "      <td>0.987041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.091459</td>\n",
       "      <td>0.987677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.088187</td>\n",
       "      <td>0.988154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-2134\n",
      "Configuration saved in runs/checkpoint-2134/config.json\n",
      "Model weights saved in runs/checkpoint-2134/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-2134/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-2134/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-4268\n",
      "Configuration saved in runs/checkpoint-4268/config.json\n",
      "Model weights saved in runs/checkpoint-4268/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-4268/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-4268/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-6402\n",
      "Configuration saved in runs/checkpoint-6402/config.json\n",
      "Model weights saved in runs/checkpoint-6402/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-6402/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-6402/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-8536\n",
      "Configuration saved in runs/checkpoint-8536/config.json\n",
      "Model weights saved in runs/checkpoint-8536/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-8536/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-8536/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-10670\n",
      "Configuration saved in runs/checkpoint-10670/config.json\n",
      "Model weights saved in runs/checkpoint-10670/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-10670/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-10670/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-12804\n",
      "Configuration saved in runs/checkpoint-12804/config.json\n",
      "Model weights saved in runs/checkpoint-12804/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-12804/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-12804/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-14938\n",
      "Configuration saved in runs/checkpoint-14938/config.json\n",
      "Model weights saved in runs/checkpoint-14938/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-14938/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-14938/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-17072\n",
      "Configuration saved in runs/checkpoint-17072/config.json\n",
      "Model weights saved in runs/checkpoint-17072/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-17072/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-17072/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-19206\n",
      "Configuration saved in runs/checkpoint-19206/config.json\n",
      "Model weights saved in runs/checkpoint-19206/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-19206/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-19206/special_tokens_map.json\n",
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12578\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to runs/checkpoint-21340\n",
      "Configuration saved in runs/checkpoint-21340/config.json\n",
      "Model weights saved in runs/checkpoint-21340/pytorch_model.bin\n",
      "tokenizer config file saved in runs/checkpoint-21340/tokenizer_config.json\n",
      "Special tokens file saved in runs/checkpoint-21340/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from runs/checkpoint-21340 (score: 0.9881539195420576).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21340, training_loss=0.025406165087234225, metrics={'train_runtime': 12343.8562, 'train_samples_per_second': 82.953, 'train_steps_per_second': 1.729, 'total_flos': 2.6932646409856058e+17, 'train_loss': 0.025406165087234225, 'epoch': 10.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir ='runs/',\n",
    "    per_device_train_batch_size=16,\n",
    "    #gradient_accumulation_steps = 2,\n",
    "    num_train_epochs=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end= True,\n",
    "    metric_for_best_model = 'accuracy',\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=_collator,\n",
    "        train_dataset=dataset['train'],\n",
    "        eval_dataset=dataset['test'],\n",
    "        tokenizer=tokenizer,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "        compute_metrics=metric_fn)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cceec8a-6c38-4bf8-b2cf-852559702925",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76657fb1-e1ff-4723-a152-91a218552058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-274b9386f5046d48\n",
      "Reusing dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-274b9386f5046d48/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2239fb8e9845eaaa4cc210459b1859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53829e905bf34949bda6772919008fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/179700 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: pair_id. If pair_id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179700\n",
      "  Batch size = 24\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2228f0b2efcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'code1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2533\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2636\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2836\u001b[0m         \"\"\"\n\u001b[1;32m   2837\u001b[0m         \u001b[0mhas_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2838\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2839\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_keys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2840\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2128\u001b[0m         \u001b[0mhandling\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m         \"\"\"\n\u001b[0;32m-> 2130\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_input\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2110\u001b[0m         \"\"\"\n\u001b[1;32m   2111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2110\u001b[0m         \"\"\"\n\u001b[1;32m   2111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_input\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2120\u001b[0m                 \u001b[0;31m# may need special handling to match the dtypes of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_deepspeed_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2122\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"csv\", data_files=\"/home/ubuntu/HwangJaewon/DL_class/test.csv\")['train']\n",
    "test_dataset = test_dataset.map(example_fn, remove_columns=['code1', 'code2'])\n",
    "\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6bd819-3f2e-4393-bed3-be156db4b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c7809fe-2e37-418e-9399-d274d1b5a64f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-6bab0a06d860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fold4_new.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('fold4_new.npy',list(predictions)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03782644-22eb-449c-a598-ed9e6eaa8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0 = np.load( 'fold0.npy')\n",
    "fold1 = np.load('fold1.npy')\n",
    "fold2 = np.load('fold2_new.npy')\n",
    "fold3 = np.load('fold3.npy')\n",
    "fold4 = np.load('fold4.npy')\n",
    "fold0_200000 = np.load('pred1.npy')\n",
    "fold0_400000 = np.load( 'pred_fold0.npy')\n",
    "pred = (fold0 + fold1+ fold2 + fold3 + fold4 + fold0_200000 + fold0_400000)/7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56333fd-e036-406d-8907-867ce992ad83",
   "metadata": {},
   "source": [
    "저장한 prediction ensemble\n",
    "모두 합쳤을 때 가장 좋은 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af44bc-7a83-4dba-bcf6-c64ada89e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "df['similar'] = np.argmax(pred, axis=-1)\n",
    "df.to_csv('ensem_all.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a88a62-2fc7-43bb-8f52-e31222c47e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similar'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2588534-a8ef-459d-8421-be552033a515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
